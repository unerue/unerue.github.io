Traceback (most recent call last):
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\jupyter_cache\executors\utils.py", line 51, in single_nb_execution
    executenb(
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "C:\Users\unerue\miniconda3\envs\vision\lib\asyncio\base_events.py", line 642, in run_until_complete
    return future.result()
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from typing import Callable
import matplotlib.pyplot as plt

import torch
from torch import nn, Tensor, optim
import torch.nn.functional as F


class ActivationFunction(nn.Module):
    def __init__(self):
        super().__init__()
        self.name = self.__class__.__name__
        self.config = {'name': self.name}


class Sigmoid(ActivationFunction):
    def forward(self, x: Tensor) -> Tensor:
        return 1 / (1 + torch.exp(-x))
    

class Tanh(ActivationFunction):
    def forward(self, x: Tensor) -> Tensor:
        x_exp, neg_x_exp = torch.exp(x), torch.exp(-x)
        return (x_exp - neg_x_exp) / (x_exp + neg_x_exp)


class ReLU(ActivationFunction):  
    def forward(self, x: Tensor) -> Tensor:
        return x * (x > 0).float()

    
act_fn_by_name = {
    'sigmoid': Sigmoid,
    'tanh': Tanh,
    'relu': ReLU,
}


def get_grads(act_fn: nn.Module, x: Tensor) -> Tensor:
    x = x.clone().requires_grad_()
    out = act_fn(x)
    out.sum().backward()
    return x.grad


def vis_act_fn(act_fn: Callable, ax: List, x: Tensor) -> None:
    y = act_fn(x)
    y_grads = get_grads(act_fn, x)
    
    x, y, y_grads = x.cpu().numpy(), y.cpu().numpy(), y_grads.cpu().numpy()
    
    ax.plot(x, y, linewidth=2, label='Activation Function')
    ax.plot(x, y_grads, linewidth=2, label='Gradient')
    ax.set_title(act_fn.name)
    ax.legend()
    ax.set_ylim(-1.5, x.max())


act_fns = [act_fn() for act_fn in act_fn_by_name.values()]
x = torch.linspace(-5, 5, 1000)

fig, axes = plt.subplots(1, 3, figsize=(9, 3))
for i, act_fn in enumerate(act_fns):
    vis_act_fn(act_fn, axes.flat[i], x)

fig.subplots_adjust(hspace=0.3)
fig.tight_layout()
plt.show()
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mNameError[0m                                 Traceback (most recent call last)
Input [1;32mIn [1][0m, in [0;36m<cell line: 46>[1;34m()[0m
[0;32m     42[0m     out[38;5;241m.[39msum()[38;5;241m.[39mbackward()
[0;32m     43[0m     [38;5;28;01mreturn[39;00m x[38;5;241m.[39mgrad
[1;32m---> 46[0m [38;5;28;01mdef[39;00m [38;5;21mvis_act_fn[39m(act_fn: Callable, ax: [43mList[49m, x: Tensor) [38;5;241m-[39m[38;5;241m>[39m [38;5;28;01mNone[39;00m:
[0;32m     47[0m     y [38;5;241m=[39m act_fn(x)
[0;32m     48[0m     y_grads [38;5;241m=[39m get_grads(act_fn, x)

[1;31mNameError[0m: name 'List' is not defined
NameError: name 'List' is not defined

