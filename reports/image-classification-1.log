Traceback (most recent call last):
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\jupyter_cache\executors\utils.py", line 51, in single_nb_execution
    executenb(
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "C:\Users\unerue\miniconda3\envs\vision\lib\asyncio\base_events.py", line 642, in run_until_complete
    return future.result()
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\unerue\miniconda3\envs\vision\lib\site-packages\nbclient\client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import torch
from torch import nn
from d2l import torch as d2l


def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),
        nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())


net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2),
    nn.Dropout(0.5),
    # There are 10 label classes
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),
    # Transform the four-dimensional output into two-dimensional output with a
    # shape of (batch size, 10)
    nn.Flatten())

X = torch.rand(size=(1, 1, 224, 224))
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__,'output shape:\t', X.shape)
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mModuleNotFoundError[0m                       Traceback (most recent call last)
Input [1;32mIn [7][0m, in [0;36m<cell line: 3>[1;34m()[0m
[0;32m      1[0m [38;5;28;01mimport[39;00m [38;5;21;01mtorch[39;00m
[0;32m      2[0m [38;5;28;01mfrom[39;00m [38;5;21;01mtorch[39;00m [38;5;28;01mimport[39;00m nn
[1;32m----> 3[0m [38;5;28;01mfrom[39;00m [38;5;21;01md2l[39;00m [38;5;28;01mimport[39;00m torch [38;5;28;01mas[39;00m d2l
[0;32m      6[0m [38;5;28;01mdef[39;00m [38;5;21mnin_block[39m(in_channels, out_channels, kernel_size, strides, padding):
[0;32m      7[0m     [38;5;28;01mreturn[39;00m nn[38;5;241m.[39mSequential(
[0;32m      8[0m         nn[38;5;241m.[39mConv2d(in_channels, out_channels, kernel_size, strides, padding),
[0;32m      9[0m         nn[38;5;241m.[39mReLU(),
[0;32m     10[0m         nn[38;5;241m.[39mConv2d(out_channels, out_channels, kernel_size[38;5;241m=[39m[38;5;241m1[39m), nn[38;5;241m.[39mReLU(),
[0;32m     11[0m         nn[38;5;241m.[39mConv2d(out_channels, out_channels, kernel_size[38;5;241m=[39m[38;5;241m1[39m), nn[38;5;241m.[39mReLU())

[1;31mModuleNotFoundError[0m: No module named 'd2l'
ModuleNotFoundError: No module named 'd2l'

